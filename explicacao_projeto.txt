Explicação do Código do Projeto:

O projeto foi estruturado em dois arquivos principais para organização e clareza: main.py e functions.py.

main.py
Este arquivo é responsável por executar as etapas de treinamento, validação e teste de modelos de aprendizado profundo para imagens histopatológicas. Ele realiza a preparação dos dados, configuração do modelo e avaliação final.

Configuração do ambiente: Inicializa o dispositivo de execução (CPU ou GPU) e define o diretório do dataset. As imagens passam por transformações como redimensionamento e normalização, além de identificar as classes do dataset.

Seleção e configuração do modelo: Permite ao usuário escolher entre diferentes modelos pré-treinados, como AlexNet, VGG, e ResNet. A camada de saída do modelo é ajustada para o número de classes presentes no dataset.

Hiperparâmetros e otimização: Define parâmetros fundamentais, como taxa de aprendizado, número de épocas, critério de perda, além de configurar o otimizador (SGD) e o scheduler para ajustar a taxa de aprendizado ao longo das épocas.

Divisão dos dados: O dataset é dividido nas proporções de 70% para treinamento, 15% para validação e 15% para teste.

Treinamento e validação: O modelo é treinado com os dados de treino, e sua performance é validada utilizando o conjunto de dados de validação.

Avaliação final: Ao final, o código calcula e exibe métricas de desempenho, como acurácia e F1-score, tanto no conjunto de validação quanto no conjunto de teste.

functions.py

criar_dataloaders()
Divide o dataset completo em três partes: treinamento (70%), validação (15%) e teste (15%), e cria os DataLoaders para cada conjunto. Ela utiliza uma semente fixa para garantir a reprodutibilidade da divisão dos dados. A função usa torch.utils.data.random_split para segmentar o dataset conforme as proporções definidas. Em seguida, imprime o número de imagens em cada conjunto e cria três DataLoaders, sendo o conjunto de treinamento embaralhado e os conjuntos de validação e teste não embaralhados. No final, a função retorna os três DataLoaders, que são usados para treinar e avaliar o modelo.

menu_modelo()
Permite ao usuário escolher entre três modelos de redes neurais pré-treinados (AlexNet, VGG16, ResNet18) e ajusta a camada de saída para o número de classes do dataset. Após a escolha, o modelo correspondente é carregado, e a última camada é modificada para ter o número correto de neurônios. A função retorna o modelo configurado. Caso o usuário escolha uma opção inválida, o programa é encerrado.

treinar_validar_e_testar()
 E responsável por treinar, validar e testar um modelo de aprendizado de máquina durante várias épocas, utilizando os conjuntos de dados de treino, validação e teste. Ela recebe os parâmetros: modelo, DataLoaders, otimizador, critério de perda, número de épocas e o dispositivo (CPU/GPU) para executar o treinamento.

Processo:
Configuração Inicial: A função define o tempo total de treinamento e inicializa listas para armazenar as perdas e acurácias de treinamento, validação e teste ao longo das épocas.

Treinamento: Durante cada época, o modelo é configurado para o modo de treinamento (modelo.train()). Para cada lote de dados de treinamento, os gradientes são zerados, o modelo gera as previsões, calcula a perda, realiza o backpropagation e atualiza os parâmetros usando o otimizador. A perda e a acurácia de treinamento são calculadas e armazenadas.

Validação: O modelo é colocado em modo de avaliação (modelo.eval()) e a validação é feita sem o cálculo do gradiente. A perda e a acurácia de validação são calculadas e armazenadas.

Teste: Após cada época, a função avalia o modelo no conjunto de teste e armazena a perda e a acurácia de teste.

Ajuste do Scheduler: Após cada época, o scheduler é atualizado para ajustar a taxa de aprendizado.

Saída: A função exibe o desempenho do modelo em termos de perdas e acurácias para cada conjunto (treinamento, validação e teste) a cada época e também calcula o tempo total de treinamento.

avaliar_e_imprimir_resultados()
Tem como objetivo avaliar o desempenho do modelo no conjunto de validação e gerar relatórios de métricas, como a matriz de confusão, o relatório de classificação e a acurácia. Ela também armazena as classes reais e preditas, bem como as probabilidades associadas às previsões feitas pelo modelo.

Processo:
Inicialização de Listas: A função começa criando listas para armazenar as classes reais (true_val_list), as classes preditas (pred_val_list) e as probabilidades de cada classe (prob_val_list) para as previsões feitas no conjunto de validação.

Iteração pelo Conjunto de Validação: A função percorre todos os lotes de dados do val_dataloader. Para cada lote:

Os dados são transferidos para o dispositivo adequado (CPU ou GPU).
O cálculo do gradiente é desabilitado (torch.set_grad_enabled(False)) para evitar que a memória seja consumida com o cálculo de gradientes durante a validação.
O modelo faz a previsão sobre as imagens do lote.
As probabilidades das previsões são calculadas usando a função softmax.
Armazenamento das Previsões: As classes reais e preditas, juntamente com as probabilidades, são armazenadas nas listas definidas anteriormente, para serem usadas nas métricas de avaliação.

Matriz de Confusão: A função calcula a matriz de confusão usando metrics.confusion_matrix, que fornece uma visão detalhada do desempenho do modelo, mostrando as previsões corretas e incorretas para cada classe.

Relatório de Classificação: Um relatório de classificação é gerado usando metrics.classification_report, que fornece métricas como precisão, recall e F1-score para cada classe.

Acurácia: A função calcula a acurácia de validação usando metrics.accuracy_score, que é a proporção de previsões corretas em relação ao total de amostras.

Impressão dos Resultados: A função exibe a matriz de confusão, o relatório de classificação e a acurácia. Além disso, chama a função imprimir_resultados_com_matriz para imprimir informações adicionais sobre o desempenho.

imprimir_resultados_com_matriz()
Imprime e exibe os resultados do treinamento, validação e teste do modelo, incluindo perdas (loss), acurácias, e a matriz de confusão, juntamente com um relatório de classificação.

Processo:
Descompactação de Resultados: A função começa descompactando a variável resultado, que contém as perdas e acurácias de treinamento, validação e teste, para variáveis individuais: train_loss_list, val_loss_list, train_acc_list, val_acc_list, test_loss_list e test_acc_list.

Impressão dos Resultados de Treinamento e Validação:

Perdas de Treinamento: A função imprime as perdas ao longo de cada época no treinamento (train_loss_list).
Perdas de Validação: Em seguida, imprime as perdas de validação por época (val_loss_list).
Acurácias de Treinamento: As acurácias durante o treinamento são impressas a partir da lista train_acc_list.
Acurácias de Validação: A função também imprime as acurácias durante a validação com base na lista val_acc_list.
Impressão dos Resultados de Teste:

Perda no Teste: A perda final no conjunto de teste é impressa a partir do último valor de test_loss_list.
Acurácia no Teste: A acurácia final no conjunto de teste é impressa a partir do último valor de test_acc_list.
Matriz de Confusão: A função calcula e imprime a matriz de confusão para a validação utilizando metrics.confusion_matrix, mostrando o desempenho do modelo em cada classe, com a contagem de previsões corretas e incorretas.

Relatório de Classificação: Um relatório de classificação detalhado é gerado com metrics.classification_report, exibindo métricas como precisão, recall, F1-score e suporte para cada classe no conjunto de validação.

Acurácia de Validação: A função imprime a acurácia na validação, calculada com metrics.accuracy_score.

Resultados:
Perdas e Acurácias: São impressas para as fases de treinamento, validação e teste.
Matriz de Confusão: Exibe a performance do modelo para cada classe.
Relatório de Classificação: Fornece uma visão detalhada da performance do modelo para cada classe, incluindo métricas como precisão, recall e F1-score.